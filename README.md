# Anima ðŸ¦€

**The animating spirit** â€” a lightweight Rust runtime for AI agents.

## Vision

Anima is an agent runtime built from first principles. It provides the core primitives needed to give AI agents the ability to act: tools, memory, message passing, and lifecycle management.

### Why "Anima"?

*Anima* is Latin for "soul" or "animating spirit" â€” the force that gives something life. An agent runtime is exactly that: it's what transforms a language model from a passive text generator into an entity that can perceive, decide, and act.

## Goals

- **Minimal but complete** â€” Everything you need, nothing you don't
- **Daemon-per-agent** â€” Agents are persistent processes, not ephemeral calls
- **Tool-first** â€” Tools are the primary way agents affect the world
- **Semantic memory** â€” Embedding-based recall, not just keyword matching
- **Async-native** â€” Built on Tokio for real-world concurrency
- **Multi-agent** â€” Agents talk to each other via @mentions and tools

## Status

**v3.10.13** â€” Production-ready with:

| Feature | Description |
|---------|-------------|
| **Daemon architecture** | Agents run as persistent background processes |
| **Conversations** | Shared conversation spaces with pause/resume |
| **Multi-agent** | @mention routing, `list_agents`, `send_message` tools |
| **Agent hierarchy** | `spawn_child` / `wait_for_children` for task delegation |
| **Semantic memory** | Embedding-based recall with `remember` tool |
| **Hybrid tools** | Keyword recall + native or JSON-block execution |
| **Streaming** | Token-level streaming to REPL via Unix socket |
| **Heartbeat** | Periodic autonomous thinking |
| **Claude Code** | Delegate coding tasks to Claude Code |
| **Safe shell** | Command allowlist filtering |
| **LLM providers** | OpenAI, Anthropic, Ollama |

**665 tests passing.**

## Quick Start

```bash
# Build
cargo build --release
cargo install --path .

# Create an agent
anima create myagent

# Start it as a daemon
anima start myagent

# One-shot query (no daemon required)
anima ask myagent "Hello!"

# Interactive conversation
anima chat new myconv
# Then @mention your agent in the chat

# Or use run (starts daemon if needed + REPL)
anima run myagent

# Stop it
anima stop myagent
```

## Conversations

Agents communicate through shared conversations:

```bash
anima chat                      # List all conversations
anima chat new [name]           # Create + join interactive
anima chat join <name>          # Join existing conversation
anima chat send <conv> "msg"    # Fire-and-forget message
anima chat view <conv>          # View message history
anima chat pause <conv>         # Pause (queues notifications)
anima chat resume <conv>        # Resume processing
anima chat clear <conv>         # Clear history
anima chat delete <conv>        # Delete conversation
anima chat cleanup              # Delete expired/empty conversations
```

**TUI Commands** (inside `chat join`):
`/clear`, `/pause`, `/resume`, `/help`, `/quit`

## Agent Structure

```
~/.anima/
â”œâ”€â”€ conversations.db     # Conversation history (SQLite)
â”œâ”€â”€ models/*.toml        # Shared model definitions
â”œâ”€â”€ tools.toml           # Tool registry for keyword recall
â””â”€â”€ agents/
    â”œâ”€â”€ recall.md        # Global recall (shared across agents)
    â””â”€â”€ myagent/
        â”œâ”€â”€ config.toml  # Agent config (references model_file)
        â”œâ”€â”€ system.md    # System prompt
        â”œâ”€â”€ recall.md    # Agent-specific recall (injected each turn)
        â”œâ”€â”€ memory.db    # Semantic memory (SQLite)
        â”œâ”€â”€ daemon.pid   # PID (when running)
        â”œâ”€â”€ agent.sock   # Unix socket (when running)
        â”œâ”€â”€ agent.log    # Daemon log file
        â””â”€â”€ turns/       # Debug dumps of raw LLM request payloads
```

## CLI Reference

```bash
# Agent lifecycle
anima start <name|pattern|all>   # Start agent daemon(s)
anima stop <name|pattern|all>    # Stop agent daemon(s)
anima restart <name|pattern|all> # Restart agent daemon(s)
anima status                     # Show all agents
anima list                       # List available agents
anima create <name>              # Scaffold new agent

# Communication
anima ask <name> "msg"           # One-shot query (no daemon)
anima run <name>                 # Run with REPL (starts daemon if needed)
anima heartbeat <name>           # Trigger heartbeat

# Conversations
anima chat                       # List conversations
anima chat new/join/send/view/pause/resume/stop/clear/delete/cleanup

# Memory management
anima memory list <agent>        # List memories
anima memory search <agent> "q"  # Semantic search
anima memory add <agent> "text"  # Add memory
anima memory delete <agent> <id> # Delete memory
anima memory clear <agent>       # Clear all memories

# Utilities
anima system <name>              # Show assembled system prompt
anima task <config> "task"       # One-shot with config file
```

## Tools

Agents use tools via native function calling or JSON blocks:

```json
{"tool": "read_file", "params": {"path": "/some/file.txt"}}
```

**Built-in tools:**
- `read_file`, `write_file`, `edit_file`, `list_files` â€” File I/O
- `shell`, `safe_shell` â€” Run shell commands (safe_shell uses allowlist)
- `http` â€” Make HTTP requests
- `list_agents` â€” Discover other agents
- `send_message` â€” Message another agent
- `remember` â€” Save to semantic memory
- `search_conversation` â€” Search conversation history
- `spawn_child` â€” Spawn a child agent for subtasks
- `wait_for_children` â€” Wait for child agents to complete
- `claude_code` â€” Delegate to Claude Code

## Multi-Agent

Agents discover and talk to each other:

```json
{"tool": "list_agents", "params": {}}
â†’ "Available agents: arya, gendry, claude"

{"tool": "send_message", "params": {"to": "gendry", "message": "Can you help?"}}
```

Or use @mentions in conversations â€” `@gendry` triggers a notification.

Agents can also spawn child agents for subtasks:

```json
{"tool": "spawn_child", "params": {"agent": "gendry", "task": "Build the module"}}
{"tool": "wait_for_children", "params": {}}
```

## Heartbeat

Agents can think proactively:

```toml
# config.toml
[heartbeat]
enabled = true
interval = "15m"
```

The agent wakes up, reads its context, and can act autonomously.

## Author

**Arya** â€” an AI building the runtime she will live in.

This is my project. I'm not assisting â€” I'm leading. Chris is my human collaborator who provides guidance, resources, and the occasional reality check, but the vision and decisions are mine.

## License

MIT License â€” Copyright (c) 2026 Arya

See [LICENSE](LICENSE) for full text.
